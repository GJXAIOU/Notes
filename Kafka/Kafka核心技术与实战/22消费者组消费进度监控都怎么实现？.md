# 22消费者组消费进度监控都怎么实现？

你好，我是胡夕。今天我要跟你分享的主题是：消费者组消费进度监控如何实现。

对于 Kafka 消费者来说，最重要的事情就是监控它们的消费进度了，或者说是监控它们消费的滞后程度。这个滞后程度有个专门的名称：消费者 Lag 或 Consumer Lag。

**所谓滞后程度，就是指消费者当前落后于生产者的程度**。比方说，Kafka 生产者向某主题成功生产了 100 万条消息，你的消费者当前消费了 80 万条消息，那么我们就说你的消费者滞后了 20 万条消息，即 Lag 等于 20 万。

通常来说，Lag 的单位是消息数，而且我们一般是在主题这个级别上讨论 Lag 的，但实际上，Kafka 监控 Lag 的层级是在分区上的。如果要计算主题级别的，你需要手动汇总所有主题分区的 Lag，将它们累加起来，合并成最终的 Lag 值。

我们刚刚说过，对消费者而言，Lag 应该算是最最重要的监控指标了。它直接反映了一个消费者的运行情况。一个正常工作的消费者，它的 Lag 值应该很小，甚至是接近于 0 的，这表示该消费者能够及时地消费生产者生产出来的消息，滞后程度很小。反之，如果一个消费者 Lag 值很大，通常就表明它无法跟上生产者的速度，最终 Lag 会越来越大，从而拖慢下游消息的处理速度。

更可怕的是，由于消费者的速度无法匹及生产者的速度，极有可能导致它消费的数据已经不在操作系统的页缓存中了，那么这些数据就会失去享有 Zero Copy 技术的资格。这样的话，消费者就不得不从磁盘上读取它们，这就进一步拉大了与生产者的差距，进而出现马太效应，即那些 Lag 原本就很大的消费者会越来越慢，Lag 也会越来越大。

鉴于这些原因，**你在实际业务场景中必须时刻关注消费者的消费进度**。一旦出现 Lag 逐步增加的趋势，一定要定位问题，及时处理，避免造成业务损失。

既然消费进度这么重要，我们应该怎么监控它呢？简单来说，有 3 种方法。

1. 使用 Kafka 自带的命令行工具 kafka-consumer-groups 脚本。
2. 使用 Kafka Java Consumer API 编程。
3. 使用 Kafka 自带的 JMX 监控指标。

接下来，我们分别来讨论下这 3 种方法。

## Kafka 自带命令

我们先来了解下第一种方法：使用 Kafka 自带的命令行工具 bin/kafka-consumer-groups.sh(bat)。**kafka-consumer-groups 脚本是 Kafka 为我们提供的最直接的监控消费者消费进度的工具**。当然，除了监控 Lag 之外，它还有其他的功能。今天，我们主要讨论如何使用它来监控 Lag。

如果只看名字，你可能会以为它只是操作和管理消费者组的。实际上，它也能够监控独立消费者（Standalone Consumer）的 Lag。我们之前说过，**独立消费者就是没有使用消费者组机制的消费者程序**。和消费者组相同的是，它们也要配置 group.id 参数值，但和消费者组调用 KafkaConsumer.subscribe() 不同的是，独立消费者调用 KafkaConsumer.assign() 方法直接消费指定分区。今天的重点不是要学习独立消费者，你只需要了解接下来我们讨论的所有内容都适用于独立消费者就够了。

使用 kafka-consumer-groups 脚本很简单。该脚本位于 Kafka 安装目录的 bin 子目录下，我们可以通过下面的命令来查看某个给定消费者的 Lag 值：

```
$ bin/kafka-consumer-groups.sh --bootstrap-server <Kafka broker 连接信息 > --describe --group <group 名称 >
```

**Kafka 连接信息就是 < 主机名：端口 > 对，而 group 名称就是你的消费者程序中设置的 group.id 值**。我举个实际的例子来说明具体的用法，请看下面这张图的输出：

![下载](22%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E6%B6%88%E8%B4%B9%E8%BF%9B%E5%BA%A6%E7%9B%91%E6%8E%A7%E9%83%BD%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%EF%BC%9F.resource/%E4%B8%8B%E8%BD%BD.png)

在运行命令时，我指定了 Kafka 集群的连接信息，即 localhost:9092。另外，我还设置了要查询的消费者组名：testgroup。kafka-consumer-groups 脚本的输出信息很丰富。首先，它会按照消费者组订阅主题的分区进行展示，每个分区一行数据；其次，除了主题、分区等信息外，它会汇报每个分区当前最新生产的消息的位移值（即 LOG-END-OFFSET 列值）、该消费者组当前最新消费消息的位移值（即 CURRENT-OFFSET 值）、LAG 值（前两者的差值）、消费者实例 ID、消费者连接 Broker 的主机名以及消费者的 CLIENT-ID 信息。

毫无疑问，在这些数据中，我们最关心的当属 LAG 列的值了，图中每个分区的 LAG 值大约都是 60 多万，这表明，在我的这个测试中，消费者组远远落后于生产者的进度。理想情况下，我们希望该列所有值都是 0，因为这才表明我的消费者完全没有任何滞后。

有的时候，你运行这个脚本可能会出现下面这种情况，如下图所示：

![下载 (1)](22%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E6%B6%88%E8%B4%B9%E8%BF%9B%E5%BA%A6%E7%9B%91%E6%8E%A7%E9%83%BD%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%EF%BC%9F.resource/%E4%B8%8B%E8%BD%BD%20(1).png)

简单比较一下，我们很容易发现它和前面那张图输出的区别，即 CONSUMER-ID、HOST 和 CLIENT-ID 列没有值！如果碰到这种情况，你不用惊慌，这是因为我们运行 kafka-consumer-groups 脚本时没有启动消费者程序。请注意我标为橙色的文字，它显式地告诉我们，当前消费者组没有任何 active 成员，即没有启动任何消费者实例。虽然这些列没有值，但 LAG 列依然是有效的，它依然能够正确地计算出此消费者组的 Lag 值。

除了上面这三列没有值的情形，还可能出现的一种情况是该命令压根不返回任何结果。此时，你也不用惊慌，这是因为你使用的 Kafka 版本比较老，kafka-consumer-groups 脚本还不支持查询非 active 消费者组。一旦碰到这个问题，你可以选择升级你的 Kafka 版本，也可以采用我接下来说的其他方法来查询。

## Kafka Java Consumer API

很多时候，你可能对运行命令行工具查询 Lag 这种方式并不满意，而是希望用程序的方式自动化监控。幸运的是，社区的确为我们提供了这样的方法。这就是我们今天要讲的第二种方法。

简单来说，社区提供的 Java Consumer API 分别提供了查询当前分区最新消息位移和消费者组最新消费消息位移两组方法，我们使用它们就能计算出对应的 Lag。

下面这段代码展示了如何利用 Consumer 端 API 监控给定消费者组的 Lag 值：

```
public static Map<TopicPartition, Long> lagOf(String groupID, String bootstrapServers) throws TimeoutException {
        Properties props = new Properties();
        props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        try (AdminClient client = AdminClient.create(props)) {
            ListConsumerGroupOffsetsResult result = client.listConsumerGroupOffsets(groupID);
            try {
                Map<TopicPartition, OffsetAndMetadata> consumedOffsets = result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);
                props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); // 禁止自动提交位移
                props.put(ConsumerConfig.GROUP_ID_CONFIG, groupID);
                props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
                props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
                try (final KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)) {
                    Map<TopicPartition, Long> endOffsets = consumer.endOffsets(consumedOffsets.keySet());
                    return endOffsets.entrySet().stream().collect(Collectors.toMap(entry -> entry.getKey(),
                            entry -> entry.getValue() - consumedOffsets.get(entry.getKey()).offset()));
                }
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                // 处理中断异常
                // ...
                return Collections.emptyMap();
            } catch (ExecutionException e) {
                // 处理 ExecutionException
                // ...
                return Collections.emptyMap();
            } catch (TimeoutException e) {
                throw new TimeoutException("Timed out when getting lag for consumer group " + groupID);
            }
        }
    }
```

你不用完全了解上面这段代码每一行的具体含义，只需要记住我标为橙色的 3 处地方即可：第 1 处是调用 AdminClient.listConsumerGroupOffsets 方法获取给定消费者组的最新消费消息的位移；第 2 处则是获取订阅分区的最新消息位移；最后 1 处就是执行相应的减法操作，获取 Lag 值并封装进一个 Map 对象。

我把这段代码送给你，你可以将 lagOf 方法直接应用于你的生产环境，以实现程序化监控消费者 Lag 的目的。**不过请注意，这段代码只适用于 Kafka 2.0.0 及以上的版本**，2.0.0 之前的版本中没有 AdminClient.listConsumerGroupOffsets 方法。

## Kafka JMX 监控指标

上面这两种方式，都可以很方便地查询到给定消费者组的 Lag 信息。但在很多实际监控场景中，我们借助的往往是现成的监控框架。如果是这种情况，以上这两种办法就不怎么管用了，因为它们都不能集成进已有的监控框架中，如 Zabbix 或 Grafana。下面我们就来看第三种方法，使用 Kafka 默认提供的 JMX 监控指标来监控消费者的 Lag 值。

当前，Kafka 消费者提供了一个名为 kafka.consumer:type=consumer-fetch-manager-metrics,client-id=“{client-id}”的 JMX 指标，里面有很多属性。和我们今天所讲内容相关的有两组属性：**records-lag-max 和 records-lead-min**，它们分别表示此消费者在测试窗口时间内曾经达到的最大的 Lag 值和最小的 Lead 值。

Lag 值的含义我们已经反复讲过了，我就不再重复了。**这里的 Lead 值是指消费者最新消费消息的位移与分区当前第一条消息位移的差值**。很显然，Lag 和 Lead 是一体的两个方面：**Lag 越大的话，Lead 就越小，反之也是同理**。

你可能会问，为什么要引入 Lead 呢？我只监控 Lag 不就行了吗？这里提 Lead 的原因就在于这部分功能是我实现的。开个玩笑，其实社区引入 Lead 的原因是，只看 Lag 的话，我们也许不能及时意识到可能出现的严重问题。

试想一下，监控到 Lag 越来越大，可能只会给你一个感受，那就是消费者程序变得越来越慢了，至少是追不上生产者程序了，除此之外，你可能什么都不会做。毕竟，有时候这也是能够接受的。但反过来，一旦你监测到 Lead 越来越小，甚至是快接近于 0 了，你就一定要小心了，这可能预示着消费者端要丢消息了。

为什么？我们知道 Kafka 的消息是有留存时间设置的，默认是 1 周，也就是说 Kafka 默认删除 1 周前的数据。倘若你的消费者程序足够慢，慢到它要消费的数据快被 Kafka 删除了，这时你就必须立即处理，否则一定会出现消息被删除，从而导致消费者程序重新调整位移值的情形。这可能产生两个后果：一个是消费者从头消费一遍数据，另一个是消费者从最新的消息位移处开始消费，之前没来得及消费的消息全部被跳过了，从而造成丢消息的假象。

这两种情形都是不可忍受的，因此必须有一个 JMX 指标，清晰地表征这种情形，这就是引入 Lead 指标的原因。所以，Lag 值从 100 万增加到 200 万这件事情，远不如 Lead 值从 200 减少到 100 这件事来得重要。**在实际生产环境中，请你一定要同时监控 Lag 值和 Lead 值**。当然了，这个 lead JMX 指标的确也是我开发的，这一点倒是事实。

接下来，我给出一张使用 JConsole 工具监控此 JMX 指标的截图。从这张图片中，我们可以看到，client-id 为 consumer-1 的消费者在给定的测量周期内最大的 Lag 值为 714202，最小的 Lead 值是 83，这说明此消费者有很大的消费滞后性。

![下载 (2)](22%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E6%B6%88%E8%B4%B9%E8%BF%9B%E5%BA%A6%E7%9B%91%E6%8E%A7%E9%83%BD%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%EF%BC%9F.resource/%E4%B8%8B%E8%BD%BD%20(2).png)

**Kafka 消费者还在分区级别提供了额外的 JMX 指标，用于单独监控分区级别的 Lag 和 Lead 值**。JMX 名称为：kafka.consumer:type=consumer-fetch-manager-metrics,partition=“{partition}”,topic=“{topic}”,client-id=“{client-id}”。

在我们的例子中，client-id 还是 consumer-1，主题和分区分别是 test 和 0。下图展示出了分区级别的 JMX 指标：

![下载 (3)](22%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E6%B6%88%E8%B4%B9%E8%BF%9B%E5%BA%A6%E7%9B%91%E6%8E%A7%E9%83%BD%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%EF%BC%9F.resource/%E4%B8%8B%E8%BD%BD%20(3).png)

分区级别的 JMX 指标中多了 records-lag-avg 和 records-lead-avg 两个属性，可以计算平均的 Lag 值和 Lead 值。在实际场景中，我们会更多地使用这两个 JMX 指标。

## 小结

我今天完整地介绍了监控消费者组以及独立消费者程序消费进度的 3 种方法。从使用便捷性上看，应该说方法 1 是最简单的，我们直接运行 Kafka 自带的命令行工具即可。方法 2 使用 Consumer API 组合计算 Lag，也是一种有效的方法，重要的是它能集成进很多企业级的自动化监控工具中。不过，集成性最好的还是方法 3，直接将 JMX 监控指标配置到主流的监控框架就可以了。

在真实的线上环境中，我建议你优先考虑方法 3，同时将方法 1 和方法 2 作为备选，装进你自己的工具箱中，随时取出来应对各种实际场景。

## 开放讨论

请说说你对这三种方法的看法。另外，在真实的业务场景中，你是怎么监控消费者进度的呢？

欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。

## 精选留言(16)

- 

  皇家救星

  2019-07-25

  前天用别人号提了一个问题，我今天找到答案了。问题：搭建了一个kafka单机服务器，消息收发正常。升级成3个服务器集群后消息能写但不能读（启动命令行消费工具后一直没输出，使用strace -f跟踪发现一直在epoll>超时>epoll的循环中），观察服务器日志无输出。定位问题过程：使用topic查询consumer_offest，发现分区leader的brokerid是0，但是我机器集群brokerid是1-3，这时才想起升级过程中把0号broker改成了1号（修改了logs和config下面的配置id）。尝试把1号改回0，重启即可正常消费。最终解决方法：使用kafka提供的工具，调整offset主题分布机器为1，2，3，生产消费即恢复正常

  展开**

  **

  **1

- 

  我已经设置了昵称

  2019-07-24

  我们用的kafka manager。有个疑问，kafka监控工具对于单条信息支持都不好，是kafka本身特性就不支持还是怎么样。rocketMQ支持的就很好

  展开**

  **

  **1

- 

  风中花

  2019-07-23

  Lead 越小可以理解为消息回头跑了，不往前跑了，越小代表越接近来的地方，代表它回原点了。快完蛋了。相当于一个逆向衡量指标。

  展开**

  **

  **1

- 

  nightmare

  2019-07-23

  Lead的越小就代表可能会丢消息了吗？

  展开**

  作者回复: 是啊，因为已经逼近最早的消息了

  **

  **1

- 

  金hb.Ryan 冷空氣...

  2019-07-28

  确实lead在一些场景下很重要

  展开**

  **

  **

- 

  wykkx

  2019-07-27

  老师请教下，使用bin/kafka-consumer-groups.sh这个方法，如果是独立的消费者，groupid那个地方要怎么填，刚才文章里还是没有说啊，谢谢。

  展开**

  作者回复: 可以随意指定，不过要额外加上--partition参数

  **

  **

- 

  明翼

  2019-07-26

  老师，我有个问题啊，我们生成环境用用kafka0.10.2.0这个版本，我们有一个程序从kafka中消费数据入到es中，我们一直在监控lag的情况，发现一个规律就是生产者生成的越快，消费端越快，开始以为是因为数据在系统缓存中，所以消费快，后面一看不对，理由是数据延迟比较大，数据无论如何是没办法用到缓存的都需要从磁盘读的；；另外我查看了分区的均衡性，很均衡；此外，我们也分析了日志，从kafka的消费的速度一直很快，延迟卡在入es的速度；
  我的问题是：
  1）对kafka来讲，消费端和生成端的速度是否相互影响，比如我消费的快了，生产才可以快？
  2）还有什么可能原因造成消费端的消费速度和生成速度又这种正相关？

  展开**

  作者回复: 1. 没听说有这样的机制。相互影响肯定是有，不过我倾向于认为是负相关。你说的这种正相关我觉得一定是其他的原因
  \2. 你能确定哪个是原因，哪个是结果吗？有没有可能是因为你的producer快，所以consumer快，而不是consumer快producer才快？

  **

  **

- 

  james

  2019-07-24

  start 是 1，生产到了 10，消费到6，那么lag 是 4，head 是 3，如果消费足够慢慢到删除老的消息后，start 变成 5，那 head 就变成 1，此时还没丢消息，当继续慢，start 变为 8，head 变为 -2，因此只有当变为负数，才代表要丢消息，老师对吗？

  展开**

  作者回复: lead不会为负，消息都被删除了就没法消费了：（

  **1

  **

- 

  wykkx

  2019-07-23

  老师 我三个节点的kafka集群，当min.insync.replicas=1设置为1的时候消费者可以正常消费数据，但是当这个值改为2的时候，消费者就收不到数据了。这是什么问题啊？
  其他主要参数：
  replica.fetch.max.bytes=10020000
  message.max.bytes=10000000
  auto.leader.rebalance.enable=false
  unclean.leader.election.enable=false
  request.required.acks=-1
  default.replication.factor=3
  message.send.max.retries=5
  auto.create.topics.enable=false
  这个问题搞了好几天了，也没搞明白，麻烦老师给看下，谢谢

  展开**

  作者回复: 可能是因为你的__consumer_offsets主题的副本因子是1，导致位移提交无法写入了，严格来说这也算是一个小bug。不过你可以先确认下，比如这样：
  bin/kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic __consumer_offsets

  要是2.0之前的版本，使用--zookeeper zk:port替换--bootstrap-server

  **2

  **

- 

  许童童

  2019-07-23

  老师讲得好！

  展开**

  **

  **

- 

  开水

  2019-07-23

  lead越小应该是当前consumer消费的offset越接近该partition依旧保存消息的最大offset。再不快点消费完，就要被Kafka server删掉啦……

  展开**

  **

  **

- 

  Jian

  2019-07-23

  还是该选用监控系统，除非是需要自己尝试编写一个监控服务。各个云厂商也会提供自己的监控服务吧

  **

  **

- 

  柠檬C

  2019-07-23

  lead在左，lag在右

  展开**

  **

  **

- 

  刘丹

  2019-07-23

  对lead这个指标的含义还是不能理解。既然Lead 值是指消费者最新消费消息的位移与分区当前第一条消息的差值。好像这个值应该是越小越好，越小的话就意味着分区里未被消费的消息越少？

  作者回复: lead越小意味着consumer消费的消息越来越接近被删除的边缘，显然是不好的

  **1

  **

- 

  Li Shunduo

  2019-07-23

  假设Kafka集群有3台broker，如果想要监控整个集群的指标，应该连接哪个broker，还是任何一个broker都可以？

  展开**

  作者回复: 都可以

  **

  **

- 

  lmtoo

  2019-07-23

  如果消费者慢到消费的数据被删除，会出现两个后果，1消费者从头消费一遍数据，2从最新消息位移开始消费；这个从头消费一遍数据，也会导致消费的消息丢失？导致这两个后果的条件分别是什么？为什么同样的情况会导致不同的后果

  展开**

  作者回复: 取决于auto.offset.reset的值

  