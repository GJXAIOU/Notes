# 答疑3 \| 第13\~18讲课后思考题答案及常见问题答疑

作者: 蒋德钧

完成时间:

总结时间:

![](<https://static001.geekbang.org/resource/image/be/f2/be981e5bb3299d488050fd6049b122f2.jpg>)

<audio><source src="https://static001.geekbang.org/resource/audio/59/33/59532d60bf3d5e6b3cf8f1a08yybf533.mp3" type="audio/mpeg"></audio>

你好，我是蒋德钧。



今天这节课，我们继续来解答第13讲到第18讲的课后思考题。这些思考题除了涉及Redis自身的开发与实现机制外，还包含了多线程模型使用、系统调用优化等通用的开发知识，希望你能掌握这些扩展的通用知识，并把它们用在自己的开发工作中。



## [第13讲](<https://time.geekbang.org/column/article/410666>)

**问题：**Redis 多IO线程机制使用startThreadedIO函数和stopThreadedIO函数，来设置IO线程激活标识io\_threads\_active为1和为0。此处，这两个函数还会对线程互斥锁数组进行解锁和加锁操作，如下所示。那么，你知道为什么这两个函数要执行解锁和加锁操作吗？

```plain
void startThreadedIO(void) {
&nbsp;&nbsp;&nbsp; ...
&nbsp;&nbsp;&nbsp; for (int j = 1; j < server.io_threads_num; j++)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pthread_mutex_unlock(&io_threads_mutex[j]);&nbsp; //给互斥锁数组中每个线程对应的互斥锁做解锁操作
&nbsp;&nbsp;&nbsp; server.io_threads_active = 1;
}
&nbsp;
void stopThreadedIO(void) {
&nbsp;&nbsp;&nbsp; ...
&nbsp;&nbsp;&nbsp; for (int j = 1; j < server.io_threads_num; j++)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pthread_mutex_lock(&io_threads_mutex[j]);&nbsp; //给互斥锁数组中每个线程对应的互斥锁做加锁操作
&nbsp;&nbsp;&nbsp; server.io_threads_active = 0;
}
```

<!-- [[[read_end]]] -->

我设计这道题的目的，主要是希望你可以了解多线程运行时，如何通过互斥锁来控制线程运行状态的变化。这里我们就来看下线程在运行过程中，是如何使用互斥锁的。通过了解这个过程，你就能知道题目中提到的解锁和加锁操作的目的了。



首先，在初始化和启动多IO线程的**initThreadedIO函数**中，主线程会先获取每个IO线程对应的互斥锁。然后，主线程会创建IO线程。当每个IO线程启动后，就会运行IOThreadMain函数，如下所示：



```plain
void initThreadedIO(void) {
&nbsp;&nbsp; …
&nbsp;&nbsp; for (int i = 0; i < server.io_threads_num; i++) {
	…
	pthread_mutex_init(&io_threads_mutex[i],NULL);
	&nbsp;io_threads_pending[i] = 0;
	&nbsp;pthread_mutex_lock(&io_threads_mutex[i]); //主线程获取每个IO线程的互斥锁
	&nbsp;if (pthread_create(&tid,NULL,IOThreadMain,(void*)(long)i) != 0) {…} //启动IO线程，线程运行IOThreadMain函数
	…} …}
```

而IOThreadMain函数会一直执行一个**while(1)**的循环流程。在这个流程中，线程又会先执行一个100万次的循环，而在这个循环中，线程会一直检查有没有待处理的任务，这些任务的数量是用**io\_threads\_pending数组**保存的。<br>

 在这个100万次的循环中，一旦线程检查到有待处理任务，也就是io\_threads\_pending数组中和当前线程对应的元素值不为0，那么线程就会跳出这个循环，并根据任务类型进行实际的处理。



下面的代码展示了这部分的逻辑，你可以看下。

```plain
void *IOThreadMain(void *myid) {
&nbsp;…
&nbsp;&nbsp;while(1) {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //循环100万次，每次检查有没有待处理的任务
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (int j = 0; j < 1000000; j++) {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (io_threads_pending[id] != 0) break;&nbsp; //如果有任务就跳出循环
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; … //从io_threads_lis中取出待处理任务，根据任务类型，调用相应函数进行处理
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }
…}
```

而如果线程执行了100万次循环后，仍然没有任务处理。那么，它就会**调用pthread\_mutex\_lock函数**去获取它对应的互斥锁。但是，就像我刚才给你介绍的，在initThreadedIO函数中，主线程已经获得了IO线程的互斥锁了。所以，在IOThreadedMain函数中，线程会因为无法获得互斥锁，而进入等待状态。此时，线程不会消耗CPU。



与此同时，主线程在进入事件驱动框架的循环前，会**调用beforeSleep函数**，在这个函数中，主线程会进一步调用handleClientsWithPendingWritesUsingThreads函数，来给IO线程分配待写客户端。

那么，在handleClientsWithPendingWritesUsingThreads函数中，如果主线程发现IO线程没有被激活的话，它就会**调用startThreadedIO函数**。



好了，到这里，startThreadedIO函数就开始执行了。这个函数中会依次调用pthread\_mutex\_unlock函数，给每个线程对应的锁进行解锁操作。这里，你需要注意的是，startThreadedIO是在主线程中执行的，而每个IO线程的互斥锁也是在IO线程初始化时，由主线程获取的。

所以，主线程可以调用pthread\_mutex\_unlock函数来释放每个线程的互斥锁。



一旦主线程释放了线程的互斥锁，那么IO线程执行的IOThreadedMain函数，就能获得对应的互斥锁。紧接着，IOThreadedMain函数又会释放释放互斥锁，并继续执行while(1)，如下所示：

```plain
void *IOThreadMain(void *myid) {
&nbsp;…
&nbsp;&nbsp;while(1) {
&nbsp;&nbsp;&nbsp;&nbsp; …
&nbsp;&nbsp;&nbsp;&nbsp; if (io_threads_pending[id] == 0) {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pthread_mutex_lock(&io_threads_mutex[id]);&nbsp; //获得互斥锁
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pthread_mutex_unlock(&io_threads_mutex[id]); //释放互斥锁
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; continue;
&nbsp;&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp; …} …}
```

那么，这里就是解答第13讲课后思考题的关键所在了。<br>

 在IO线程释放了互斥锁后，主线程可能正好在执行handleClientsWithPendingWritesUsingThreads函数，这个函数中除了刚才介绍的，会根据IO线程是否激活来启动IO线程之外，它也会**调用stopThreadedIOIfNeeded函数，来判断是否需要暂停IO线程**。

stopThreadedIOIfNeeded函数一旦发现待处理任务数，不足IO线程数的2倍，它就会调用stopThreadedIO函数来暂停IO线程。



**而暂停IO线程的办法，就是让主线程获得线程的互斥锁。**所以，stopThreadedIO函数就会依次调用pthread\_mutex\_lock函数，来获取每个IO线程对应的互斥锁。刚才我们介绍的IOThreadedMain函数在获得互斥锁后，紧接着就释放互斥锁，其实就是希望主线程执行的stopThreadedIO函数，能在IO线程释放锁后的这个时机中，获得线程的互斥锁。



这样一来，因为IO线程执行IOThreadedMain函数时，会一直运行while(1)循环，并且一旦判断当前待处理任务为0时，它会去获取互斥锁。而此时，如果主线程已经拿到锁了，那么IO线程就只能进入等待状态了，这就相当于暂停了IO线程。



这里，你还需要注意的一点是，**stopThreadedIO函数还会把表示当前IO线程激活的标记io\_threads\_active设为0**，这样一来，主线程的handleClientsWithPendingWritesUsingThreads函数在执行时，又会根据这个标记来再次调用startThreadedIO启用IO线程。而就像刚才我们提到的，startThreadedIO函数会释放主线程拿的锁，让IO线程从等待状态进入运行状态。



关于这道题，不少同学都提到了，题目中所说的加解锁操作是为了控制IO线程的启停，而且像是@土豆种南城同学，还特别强调了IOThreadedMain函数中执行的100万次循环的作用。



因为这个题目涉及的锁操作在好几个函数间轮流执行，所以，我刚才也是把这个过程的整体流程给你做了解释。下面我也画了一张图，展示了主线程通过加解锁控制IO线程启停的基本过程，你可以再整体回顾下。



![图片](<https://static001.geekbang.org/resource/image/c3/01/c3d8dc9c44db04d15975cf8bfa4f0401.jpg?wh=1920x1039>)

## [第14讲](<https://time.geekbang.org/column/article/411558>)

**问题：**如果我们将命令处理过程中的命令执行也交给多IO线程执行，你觉得除了对原子性有影响，会有什么好处或其他不足的影响吗？



这道题主要是希望你能对多线程执行模型的优势和不足，有进一步的思考。



其实，使用多IO线程执行命令的好处很直接，就是可以充分利用CPU的多核资源，让每个核上的IO线程并行处理命令，从而提升整体的吞吐率。



但是，这里你要注意的是，如果多个命令执行时要对同一个数据结构进行写操作，那么，此时也就是多个线程要并发写某个数据结构。为了保证操作正确性，我们就需要使用**互斥方法**，比如加锁，来提供并发控制。

这实际上是使用多IO线程时的不足，它会带来两个影响：一个是基于加锁等互斥操作的并发控制，会降低系统整体性能；二个是多线程并发控制的开发与调试比较难，会增加开发者的负担。



## [第15讲](<https://time.geekbang.org/column/article/412164>)

**问题：**Redis源码中提供了getLRUClock函数来计算全局LRU时钟值，同时键值对的LRU时钟值是通过LRU\_CLOCK函数来获取的，以下代码也展示了LRU\_CLOCK函数的执行逻辑，这个函数包括了两个分支，一个分支是直接从全局变量server的lruclock中获取全局时钟值，另一个是调用getLRUClock函数获取全局时钟值。

那么你知道，为什么键值对的LRU时钟值，不直接通过调用getLRUClock函数来获取呢？

```plain
unsigned int LRU_CLOCK(void) {
&nbsp;&nbsp;&nbsp; unsigned int lruclock;
&nbsp;&nbsp;&nbsp; if (1000/server.hz <= LRU_CLOCK_RESOLUTION) {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; atomicGet(server.lruclock,lruclock);
&nbsp;&nbsp;&nbsp; } else {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; lruclock = getLRUClock();
&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp;&nbsp; return lruclock;
}
```

这道题有不少同学都给出了正确答案，比如@可怜大灰狼、@Kaito、@曾轼麟等等。这里我来总结下。



其实，调用getLRUClock函数获取全局时钟值，它最终会调用**gettimeofday**这个系统调用来获取时间。而系统调用会触发用户态和内核态的切换，会带来微秒级别的开销。

而对于Redis来说，它的吞吐率是每秒几万QPS，所以频繁地执行系统调用，这里面带来的微秒级开销有些大。所以，**Redis只是以固定频率调用getLRUClock函数**，使用系统调用获取全局时钟值，然后将该时钟值赋值给全局变量server.lruclock。当要获取时钟时，直接从全局变量中获取就行，节省了系统调用的开销。



刚才介绍的这种实现方法，在系统的性能优化过程中是有不错的参考价值的，你可以重点掌握下。



## [第16讲](<https://time.geekbang.org/column/article/413038>)

**问题：**LFU算法在初始化键值对的访问次数时，会将访问次数设置为LFU\_INIT\_VAL，它的默认值是5次。那么，你能结合这节课介绍的代码，说说如果LFU\_INIT\_VAL设置为1，会发生什么情况吗？



这道题目主要是希望你能理解LFU算法实现时，对键值对访问次数的增加和衰减操作。**LFU\_INIT\_VAL会在LFULogIncr函数中使用**，如下所示：

```plain
uint8_t LFULogIncr(uint8_t counter) {
…
double r = (double)rand()/RAND_MAX;
&nbsp;&nbsp;&nbsp; double baseval = counter - LFU_INIT_VAL;
&nbsp;&nbsp;&nbsp; if (baseval < 0) baseval = 0;
&nbsp;&nbsp;&nbsp; double p = 1.0/(baseval*server.lfu_log_factor+1);
	if (r < p) counter++;
	…}
```

从代码中可以看到，如果LFU\_INIT\_VAL比较小，那么baseval值会比较大，这就导致p值比较小，那么counter++操作的机会概率就会变小，这也就是说，键值对访问次数counter不容易增加。

而另一方面，**LFU算法在执行时，会调用LFUDecrAndReturn函数**，对键值对访问次数counter进行衰减操作。counter值越小，就越容易被衰减后淘汰掉。所以，如果LFU\_INIT\_VAL值设置为1，就容易导致刚刚写入缓存的键值对很快被淘汰掉。

因此，为了避免这个问题，LFU\_INIT\_VAL值就要设置的大一些。



## [第17讲](<https://time.geekbang.org/column/article/413997>)

**问题：**freeMemoryIfNeeded函数在使用后台线程删除被淘汰数据的时候，你觉得在这个过程中，主线程仍然可以处理外部请求吗？



这道题像@Kaito等不少同学都给出了正确答案，我在这里总结下，也给你分享一下我的思考过程。

Redis主线程在执行freeMemoryIfNeeded函数时，这个函数确定了淘汰某个key 之后，会先把这个key从全局哈希表中删除。然后，这个函数会在dbAsyncDelete函数中，**调用lazyfreeGetFreeEffort函数，评估释放内存的代价。**

这个代价的计算，主要考虑的是要释放的键值对是集合时，集合中的元素数量。如果要释放的元素过多，主线程就会在后台线程中执行释放内存操作。此时，主线程就可以继续正常处理客户端请求了。而且因为被淘汰的key已从全局哈希表中删除，所以客户端也查询不到这个key了，不影响客户端正常操作。



## [第18讲](<https://time.geekbang.org/column/article/415563>)

**问题：**你能在serverCron函数中，查找到rdbSaveBackground函数一共会被调用执行几次么？这又分别对应了什么场景呢？



这道题，我们通过在serverCron函数中查找**rdbSaveBackground函数**，就可以知道它被调用执行了几次。@曾轼麟同学做了比较详细的查找，我整理了下他的答案，分享给你。



首先，在serverCron 函数中，它会直接调用rdbSaveBackground两次。



**第一次直接调用**是在满足RDB生成的条件时，也就是修改的键值对数量和距离上次生成RDB的时间满足配置阈值时，serverCron函数会调用rdbSaveBackground函数，创建子进程生成RDB，如下所示：

```plain
if (server.dirty >= sp->changes && server.unixtime-server.lastsave > sp->seconds &&
(server.unixtime-server.lastbgsave_try> CONFIG_BGSAVE_RETRY_DELAY
|| server.lastbgsave_status == C_OK)) {
…
rdbSaveBackground(server.rdb_filename,rsiptr);
…}
```

**第二次直接调用**是在客户端执行了BGSAVE命令后，Redis设置了rdb\_bgsave\_scheduled等于1，此时，serverCron函数会检查这个变量值以及当前RDB子进程是否运行。

如果子进程没有运行的话，那么serverCron函数就调用rdbSaveBackground函数，生成RDB，如下所示：

```plain
if (!hasActiveChildProcess() && server.rdb_bgsave_scheduled &&
(server.unixtime-server.lastbgsave_try > CONFIG_BGSAVE_RETRY_DELAY ||
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; server.lastbgsave_status == C_OK)) {
&nbsp;…
if (rdbSaveBackground(server.rdb_filename,rsiptr) == C_OK)
…}
```

而除了刚才介绍的两次直接调用以外，在serverCron函数中，还会有两次对rdbSaveBackground的**间接调用**。



一次间接调用是通过replicationCron -> startBgsaveForReplication -> rdbSaveBackground这个调用关系，来间接调用rdbSaveBackground函数，为主从复制定时任务生成RDB文件。



另一次间接调用是通过checkChildrenDone –> backgroundSaveDoneHandler -> backgroundSaveDoneHandlerDisk -> updateSlavesWaitingBgsave -> startBgsaveForReplication -> rdbSaveBackground这个调用关系，来生成RDB文件的。而这个调用主要是考虑到在主从复制过程中，有些从节点在等待当前的RDB生成过程结束，因此在当前的RDB子进程结束后，这个调用为这些等待的从节点新调度启动一次RDB子进程。



## 小结

好了，今天这节课就到这里了。我来总结下。



在今天的课程上，我给你解答了第13讲到第18讲的课后思考题。在这其中，我觉得有两个内容是你需要重点掌握的。

**一个是你要了解系统调用的开销**。从绝对值上来看，系统调用开销并不高，但是对于像Redis这样追求高性能的系统来说，每一处值得优化的地方都要仔细考虑。避免额外的系统开销，就是高性能系统开发的一个重要设计指导原则。



**另一个是多IO线程模型的使用**。我们通过思考题，了解了Redis会通过线程互斥锁，来实现对线程运行和等待状态的控制，以及多线程的优点和不足。现在的服务器硬件都是多核CPU，所以多线程模型也被广泛使用，用好多线程模型可以帮助我们实现系统性能的提升。

所以在最后，我也再给你关于多线程模型开发的三个小建议：

- 尽量减少共享数据结构的使用，比如采用key partition的方法，让每个线程负责一部分key的访问，这样可以减少并发访问的冲突。当然，如果要做范围查询，程序仍然需要访问多个线程负责的key。
- 对共享数据结构进行优化，尽量采用原子操作来减少并发控制的开销。
- 将线程和CPU核绑定，减少线程在不同核上调度时带来的切换开销。

<!-- -->

欢迎继续给我留言，分享你在学习课程时的思考。

