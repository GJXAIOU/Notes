# 31 | 模块答疑：为什么大数据平台至关重要？

你好，我是李智慧。今天我来做模块四的答疑，主题是为什么大数据平台至关重要。

我前面说过，软件大体可以分为两种，一种是为最终用户开发的，实现用户需要的业务功能；另一种是为软件工程师开发的，供软件工程师使用。我在专栏前三个模块讲到的各种大数据产品，都属于后一种，最终用户不可能自己提交一个 Hadoop 程序去执行大数据计算，这是软件工程师的工作，因此大数据产品也是为软件工程师开发的。而如何让软件工程师能够便捷地提交各类大数据计算程序给大数据计算引擎去执行，如何将用户实时数据转化为大数据产品的数据源，如何利用好大数据的计算结果，这些都是大数据平台的职责范围。

**大数据平台将互联网应用和大数据产品整合起来，构建成一个完整的系统，将实时数据和离线数据打通，使数据可以实现更大规模的关联计算，挖掘出数据更大的价值，从而实现数据驱动业务，通过数据统计发现业务规律（也就是机器学习模型）**。而利用这个规律对未来的数据进行分类和预测，使系统呈现出智能的特性，也为互联网未来发展和人类的生产生活创造了无限可能。

大数据平台将互联网应用和大数据产品整合起来，一方面使互联网应用变得更加智能、强大；一方面也使得大数据产品实现技术落地。技术不同于科学，科学拓展人类的认知边界，而技术是人们改造世界的工具，科学的成果可以转化为技术；而技术真正能够改造世界，需要技术落地，真正应用到生产过程中。用我们熟知的 Hadoop 为例，即使它的技术再厉害，如果没有具体应用，没有被广泛使用，同样也很难说明它有多大的价值。所以技术落地使技术产品实现真正价值，也正是大数据平台使得大数据技术产品可以落地应用，实现了自身价值。

所以，大数据平台不但对应用至关重要，对各种大数据技术产品也至关重要。事实上，大数据平台对大数据工程师的技术进阶也非常重要。

这些年来，多次有同学向我咨询如何成为软件架构师。软件架构师，顾名思义，就是从事软件架构设计的那个人。而关于软件架构，其定义是“关于软件各个组成部分及其关系的描述”，所以**软件架构师就是对软件各个组成部分及其关系进行设计和描述的那个人**。软件的各个组成部分包括业务组件模块，比如用户管理模块、订单处理模块，也包括技术组件，比如缓存组件、消息队列组件，当然还有大数据技术组件。

**软件架构师要想设计出一个符合业务场景，便于开发维护的软件架构，必须要对业务很熟悉，还要对技术很精通。要将复杂的业务拆分成较小的、低耦合高内聚的、便于开发维护的模块；还要对各种技术组件的功能特性、技术原理、使用和调优方法很熟悉。软件架构师需要选择合适的技术组件应用到自己的软件架构中，并在将来的开发使用过程中指导工程师正确使用这些技术组件，还要能根据业务需要对这些技术组件进行适当的调优甚至改造**。

所以，我的观点是，**从按照需求进行业务功能开发的程序员进阶到软件架构师，并不是随着经验积累、工作年限的增加就能自动能完成的**。如果你一直按照别人给定的技术架构和业务需求开发代码，你很难从更高的层面去思考软件的架构是如何设计出来的，也缺乏明确的目标去掌握那些真正有难度的、底层的技术。

因此帮助你实现技术进阶，同样也是这个专栏当初设计的一个初衷。专栏前面三个模块希望你能了解、掌握大数据技术产品组件的原理，然后通过模块四，将各种大数据技术产品融会贯通，应用到自己的开发实践中，构建一个大数据平台。而通过专栏系统的学习，一方面可以实现大数据的业务价值，另一方面也可以使自己从业务开发者的角色，逐步进阶成为软件架构设计者的角色。

我的专栏的名字叫《从 0 开始学大数据》，确实不需要你有任何大数据背景就可以跟着专栏开始学习大数据，但是我并不希望你学完专栏后，还只是打了一个大数据的基础，我更希望你能掌握构建大数据系统大厦的能力。这当然会有难度，学习过程中也会有挫折感，但是我依然希望你能坚持学习，即使有些技术不能完全掌握，但是至少可以让你的视野达到一个更高的高度，去感受架构师如何思考架构设计，并可以把收获应用到未来的学习工作中，让自己有不断进步的目标和动力。

下面我来回答一下“helloWorld”同学提出的一个问题。

![image-20230416222953572](31_%E6%A8%A1%E5%9D%97%E7%AD%94%E7%96%91%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E8%87%B3%E5%85%B3%E9%87%8D%E8%A6%81%EF%BC%9F.resource/image-20230416222953572.png)

老实说我没有做过这类产品的开发，也不太了解腾讯的这个流计算平台，仅仅说一下我对这个功能实现的思路。

通过前面的学习我们知道，Spark 实现分布式计算的最小单位是计算任务（Task），每个任务针对一个不同数据分片进行计算，相同的一组任务组成一个任务集（TaskSet），通常一个任务集就是一个计算阶段（Stage），所有的计算阶段组成一个有向无环图（DAG）。

所以这个有向无环图就是 Spark 分布式计算的核心，根据这个有向无环图的依赖关系，不断地将任务分发给计算集群去计算，每个计算进程领到计算任务后，执行任务对应的代码，最后完成大数据计算。

既然根据大数据应用程序代码可以生成有向无环图，那么能不能直接把这个有向无环图画出来，然后根据这个有向无环图进行分布式计算呢？当然可以，这就是问题中提到的可视化编程的思路。

我在[专栏第 12 期](http://time.geekbang.org/column/article/69822)讲 Spark 编程时提到，我们了解到 Spark 提供了一组针对大数据的计算函数，包括转换函数和执行函数两种，事实上每个计算任务就是由一个或多个这样的函数构成的。那么可视化编程的时候，只需要将这些函数拖动过来根据数据处理逻辑组成有向无环图即可。

我们还知道，Spark 的这些计算函数的输入参数是另外一个函数，也就是真正的运行逻辑，比如 fliter 函数的输入是一个布尔表达式，比如 x > 100，以判断数据是否进行下一步处理。

所以这样一个可视化编程环境也会预置一些这样函数，以可视化节点的形式提供，开发者拖动这些节点，并在节点上输入一些简单表达式（或者拖动一些表达式符号和字段名称进来），就可以完成大数据可视化编程了。我画了一个简单的示意图。

![img](31_%E6%A8%A1%E5%9D%97%E7%AD%94%E7%96%91%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E8%87%B3%E5%85%B3%E9%87%8D%E8%A6%81%EF%BC%9F.resource/image-20230416223006524.png)

开发这样的有向无环图的可视化编辑工具技术非常成熟，只要根据这个图形生成一个 XML 之类的描述文件，交给一个执行引擎去执行就可以了。

至于如何根据一个 XML 文件执行计算逻辑，可以参考 Hive 的实现。在[专栏第 11 期](http://time.geekbang.org/column/article/69459)我们也学习过，Hive QL 经过语法分析、语义解析与优化后生成一个执行计划，这个执行计划也是一个有向无环图。Hive 用 XML 描述这个有向无环图，并提交给 Hive 的执行引擎，执行引擎解析 XML，并利用 Hive 内置的 Operator 算子构建 MapReduce 作业，提交给 Hadoop 执行。

有兴趣的同学可以在 Spark 上尝试一下，根据 XML 生成 Spark 代码，再把这个代码编译后提交给 Spark 引擎执行，这个过程应该并不难。

最后我贴出@纯洁的憎恶、@方得始终、@杰之 7、@小千、@warm_day 这几位同学的留言，希望他们的思考对你也有所启发。

![image-20230416223039364](31_%E6%A8%A1%E5%9D%97%E7%AD%94%E7%96%91%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E8%87%B3%E5%85%B3%E9%87%8D%E8%A6%81%EF%BC%9F.resource/image-20230416223039364.png)

![image-20230416223100667](31_%E6%A8%A1%E5%9D%97%E7%AD%94%E7%96%91%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E8%87%B3%E5%85%B3%E9%87%8D%E8%A6%81%EF%BC%9F.resource/image-20230416223100667.png)

![image-20230416223112651](31_%E6%A8%A1%E5%9D%97%E7%AD%94%E7%96%91%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E8%87%B3%E5%85%B3%E9%87%8D%E8%A6%81%EF%BC%9F.resource/image-20230416223112651.png)



欢迎你点击“请朋友读”，把今天的文章分享给好友。也欢迎你写下自己的思考或疑问，与我和其他同学一起讨论。

## 精选留言

- 授之于鱼不如授之于渔，思想比工具更重要。这也许就是专栏老师的用意所在。🤔

- 陈述了现实困境，业务开发很难掌握底层技术，甚至找不到学习目标，但并没有良方解药

- 是啊，正如楼上所说，我们好像没有从大数据平台中看到容器的身影…… 老师可否稍微提一下……

  作者回复: yarn 有自己的 container，详情 yarn 一期专栏

- 通过这一节的阅读学习，能进一步加深我对大数据平台的理解。

  在文章中老师讲到数据驱动业务，就是大数据产品和应用产品的结合，通过我们每一步的点击、浏览，重复使用之后，大数据产品通过统计，进行机器训练，然后得到有价值的信息反馈给我们。

  学习到这里，大数据产品和平台也就接近尾声了，后面两章节分析和算法部分，也需要我们认真学习。到这里，我希望老师开一个实战篇的专栏，期望实战的内容同这一个专栏一样对我们同学有价值。感谢老师。

  展开**

- 大数据技术及其生态链的演进过程耐人寻味，与其说是技术进步，不如说是应用场景引导的互联网“基础设施变革”。进入新世纪，快速增长的互联网企业，积累了庞大的数据，以至于无法使用传统手段处理，它们开始探索新方法，大数据技术就这么诞生了。随后市场逐渐出现了开源平台，让更多的互联网企业可以参与进来，也吸引着越来越多的开发者加入到这个新鲜的领域。于是大量的新需求推动了大数据工具不断向上封装，使得大数据技术门槛大大降低、使用越来越方便。同时，摩尔定律、网络基础设施的完善与提速、数据获取日益简便，使得大数据技术应用成本也在大大下降。各行各业纷纷涌入，疯狂捆绑在大数据战车上为彼此赋能。大数据服务也随之快速商业化，朝着“飞入寻常百姓家”的方向飞奔。大数据就像是高深的掘井技术，一步步变成了只要打开水龙头就能获取的日常资源。也许未来大数据（人工智能）、IoT、区块链会成为智能社会的三驾马车。就像电力系统、自来水系统、燃气系统、公共交通系统之于工业化城市一样。

  展开**

- 老师，目前基于容器的云平台越发大行其道，spark 也对 k8s 支持越来越好。感觉正在蚕食 hadoop 平台，未来基于容器云的大数据、人工智能是否会成为新的标准？对于大数据开发者来说，我们是否需要自己尝试向云平台看齐？需要做怎样的努力？

  作者回复: 不同容器只是多一种部署方案，对开发者多一种选择，能替代的只是 yarn，存储计算才是大数据的核心。对于大数据运维环境，顺势而为即可。