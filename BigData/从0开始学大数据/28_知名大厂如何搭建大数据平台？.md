# 28 | 知名大厂如何搭建大数据平台？

专栏第 26 期，我介绍了一个常规的大数据平台架构方案，这种架构方案是基于大数据平台 Lamda 架构进行设计的。事实上，业界也基本是按照这种架构模型搭建自己的大数据平台。

今天我们来看一下淘宝、美团和滴滴的大数据平台，一方面进一步学习大厂大数据平台的架构，另一方面也学习大厂的工程师如何画架构图。通过大厂的这些架构图，你就会发现，不但这些知名大厂的大数据平台设计方案大同小异，架构图的画法也有套路可以寻觅。

## 一、淘宝大数据平台

淘宝可能是中国互联网业界较早搭建了自己大数据平台的公司，下图是淘宝早期的 Hadoop 大数据平台，比较典型。

![image-20230416222154658](28_%E7%9F%A5%E5%90%8D%E5%A4%A7%E5%8E%82%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%EF%BC%9F.resource/image-20230416222154658.png)

淘宝的大数据平台基本也是分成三个部分，上面是数据源与数据同步；中间是云梯 1，也就是淘宝的 Hadoop 大数据集群；下面是大数据的应用，使用大数据集群的计算结果。

数据源主要来自 Oracle 和 MySQL 的备库，以及日志系统和爬虫系统，这些数据通过数据同步网关服务器导入到 Hadoop 集群中。其中 DataExchange 非实时全量同步数据库数据，DBSync 实时同步数据库增量数据，TimeTunnel 实时同步日志和爬虫数据。数据全部写入到 HDFS 中。

![image-20230416222210649](28_%E7%9F%A5%E5%90%8D%E5%A4%A7%E5%8E%82%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%EF%BC%9F.resource/image-20230416222210649.png)

在 Hadoop 中的计算任务会通过天网调度系统，根据集群资源和作业优先级，调度作业的提交和执行。计算结果写入到 HDFS，再经过 DataExchange 同步到 MySQL 和 Oracle 数据库。处于平台下方的数据魔方、推荐系统等从数据库中读取数据，就可以实时响应用户的操作请求。

淘宝大数据平台的核心是位于架构图左侧的天网调度系统，提交到 Hadoop 集群上的任务需要按序按优先级调度执行，Hadoop 集群上已经定义好的任务也需要调度执行，何时从数据库、日志、爬虫系统导入数据也需要调度执行，何时将 Hadoop 执行结果导出到应用系统的数据库，也需要调度执行。可以说，整个大数据平台都是在天网调度系统的统一规划和安排下进行运作的。

DBSync、TimeTunnel、DataExchange 这些数据同步组件也是淘宝内部开发的，可以针对不同的数据源和同步需求进行数据导入导出。这些组件淘宝大都已经开源，我们可以参考使用。

## 二、美团大数据平台

美团大数据平台的数据源来自 MySQL 数据库和日志，数据库通过 Canal 获得 MySQL 的 binlog，输出给消息队列 Kafka，日志通过 Flume 也输出到 Kafka。

![image-20230501170324471](28_%E7%9F%A5%E5%90%8D%E5%A4%A7%E5%8E%82%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%EF%BC%9F.resource/image-20230501170324471.png)

Kafka 的数据会被流式计算和批处理计算两个引擎分别消费。流处理使用 Storm 进行计算，结果输出到 HBase 或者数据库。批处理计算使用 Hive 进行分析计算，结果输出到查询系统和 BI（商业智能）平台。

数据分析师可以通过 BI 产品平台进行交互式的数据查询访问，也可以通过可视化的报表工具查看已经处理好的常用分析指标。公司高管也是通过这个平台上的天机系统查看公司主要业务指标和报表。

美团大数据平台的整个过程管理通过调度平台进行管理。公司内部开发者使用数据开发平台访问大数据平台，进行 ETL（数据提取、转换、装载）开发，提交任务作业并进行数据管理。

## 三、滴滴大数据平台

滴滴大数据平台分为实时计算平台（流式计算平台）和离线计算平台（批处理计算平台）两个部分。

实时计算平台架构如下。数据采集以后输出到 Kafka 消息队列，消费通道有两个，一个是数据 ETL，使用 Spark Streaming 或者 Flink 将数据进行清洗、转换、处理后记录到 HDFS 中，供后续批处理计算。另一个通道是 Druid，计算实时监控指标，将结果输出到报警系统和实时图表系统 DashBoard。

![image-20230416222301588](28_%E7%9F%A5%E5%90%8D%E5%A4%A7%E5%8E%82%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%EF%BC%9F.resource/image-20230416222301588.png)

离线计算平台架构如下。滴滴的离线大数据平台是基于 Hadoo 2（HDFS、Yarn、MapReduce）和 Spark 以及 Hive 构建，在此基础上开发了自己的调度系统和开发系统。调度系统和前面其他系统一样，调度大数据作业的优先级和执行顺序。开发平台是一个可视化的 SQL 编辑器，可以方便地查询表结构、开发 SQL，并发布到大数据集群上。

![image-20230416222311786](28_%E7%9F%A5%E5%90%8D%E5%A4%A7%E5%8E%82%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%EF%BC%9F.resource/image-20230416222311786.png)

此外，滴滴还对 HBase 重度使用，并对相关产品（HBase、Phoenix）做了一些自定义的开发，维护着一个和实时、离线两个大数据平台同级别的 HBase 平台，它的架构图如下。

![img](28_%E7%9F%A5%E5%90%8D%E5%A4%A7%E5%8E%82%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%EF%BC%9F.resource/image-20230416222321131.png)

来自于实时计算平台和离线计算平台的计算结果被保存到 HBase 中，然后应用程序通过 Phoenix 访问 HBase。而 Phoenix 是一个构建在 HBase 上的 SQL 引擎，可以通过 SQL 方式访问 HBase 上的数据。

## 小结

你可以看到，这些知名大厂的大数据平台真的是大同小异，他们根据各自场景和技术栈的不同，虽然在大数据产品选型和架构细节上略有调整，但整体思路基本上都是一样的。

不过也正是这种大同小异，让我们从各个角度更加了解大数据平台架构，对大数据平台架构有了更加深刻的认知。

我在阿里巴巴工作期间，有一阵子不断参加各种基础技术产品的架构评审会。有一次，另一个和我一样经常参加这类会议的架构师说：“我感觉这些产品的架构怎么都一样”。被他一说，大家都纷纷点头称是，好像确实如此。

同一类问题的解决方案通常也是相似的。**一个解决方案可以解决重复出现的同类问题，这种解决方案就叫作模式**。模式几乎是无处不在的，一旦一个解决方案被证明是行之有效的，就会被重复尝试解决同类的问题。

所以我们看到，很多大数据产品的架构也都是差不多的，比如 Hadoop 1、Yarn、Spark、Flink、Storm，这些产品的部署架构真的是太像了。

对于有志于成为架构师的工程师来说，一方面当然是提高自己的编程水平，另一方面也可以多看看各种架构设计文档，多去参加一些架构师技术大会。在我看来，编程需要天分；而架构设计，真的是孰能生巧。

## 思考题

下图是腾讯的大数据平台架构，请你尝试对这个架构图的主要组件和运行机制进行分析。

![image-20230416222338304](28_%E7%9F%A5%E5%90%8D%E5%A4%A7%E5%8E%82%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%EF%BC%9F.resource/image-20230416222338304.png)

欢迎你点击“请朋友读”，把今天的文章分享给好友。也欢迎你写下自己的思考或疑问，与我和其他同学一起讨论。

## 精选留言(8)

- 我们公司是做互联网金融的，流处理需求很少，大多都是批处理之后生成的报表
  每天基本上就是用 sqoop 增量的把 MySQL 中前一天的业务数据导入到 hive。然后做一些业务上的报表计算，另外还有我负责的风控中请求的几个第三方数据，每天大概有五六十 GB 的样子，还有用户的通讯录数据等，以及一些相关报表的计算，数据量的话多的也就二三十亿条，离线计算都是 Spark on yarn，调度系统是 azkaban。
  因为现在没有业务需求会用到 hbase，
  有很少的埋点数据，用 kafka，Sparkstreaming 处理一下。
  感觉现在的那些批处理的东西都用的差不多了，天天觉得没啥有挑战的事情做，觉得心里挺空的，想过了年换工作，但是目前，各大公司也都在裁员，很是纠结。希望老师给点建议😁

  展开**

  作者回复: 多了解业务，了解哪些业务的问题可以用大数据解决，走出去而不是等需求，多学习大数据的知识，扩展知识面，思考哪些大数据技术可以用到自己的工作中，会有很多机会的
  
- Apache Airflow 是一个的编排，调度和监控工作流的开源工具。它的工作流设计是基于 DAG，而且是用 Python 来编写，可以说是 workflow as code。我目前正在学习使用。

  展开**

- 通过这一节的阅读，熟悉了各大互联网公司的大数据平台。大致模式是通过某种方式，对数据库中的数据进行提取，导入到大数据平台中，然后对数据平台的数据进行计算，返回可使用的数据。

  对整个过程的调度和把控，淘宝、美团、滴滴各自用自身公司开发的调度管理系统，处理调度的优先级和执行顺序。

  生活在今天这个时代，每个人都能享受这种数据智能的便捷，除了计算机本身的功能，更有一大批从事数据工作的人为我们提供了这样的服务。数据能如此精准，那同样我们对于我们的工作和生活，也应有像数据人那样，认真对待，这样才会工作之余更好的跟上数据智能时代的节奏，把握我们自身的生活。

  展开**
