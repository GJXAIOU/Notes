# 02讲日志系统：一条SQL更新语句是如何执行的

建表语句，这个表有一个主键 id 和一个整型字段 c：

```mysql
create table T(
id int primary key, 
c int
);
```

然后使用更新语句：将 id = 2 这一行的值加 1

```mysql
update T set c = c+1 where id=2;
```

和查询语句执行链路类似，执行该更新语句前要先通过连接器连接数据库。

**在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空**。这也就是一般不建议使用查询缓存的原因。

接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 id 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。

连接器 =》清空表上所有查询缓存 =》 分析器 =》 执行器

与查询流程不一样的是，更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog（归档日志）。

## 一、重做日志：redo log

redo log 是记录了 InnoDB 存储引擎的事务日志，当数据库实例失败时候 InnoDB 会通过重做日志恢复到掉电前的时刻来保证数据的完整性。

在 MySQL，**如果**每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，**MySQL 使用 WAL（Write-Ahead Logging）技术。关键点就是先写日志，再写磁盘。**

**具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log 里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。**

InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头**循环写**，如下面这个图所示。

![image-20200630163715085](02讲日志系统：一条SQL更新语句是如何执行的.resource/image-20200630163715085-1608210552509-1608210582923.png)

- `write pos` 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。`checkpoint` 是当前要擦除的位置，也是往后推移并且循环，**擦除记录前要把记录更新到数据文件**。

- `write pos` 和 `checkpoint`之间的是还空着的部分【就是 `write pos` 到 3 号文件末尾，再加上 `0`号文件开头到 `checkpoint` 的部分】，可以用来记录新的操作。如果 `write pos` 追上 `checkpoint`，表示满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。

- 有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 **crash-safe**。

## 二、二进制日志：binlog

MySQL 整体分为两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面放入 **redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。**

为什么会有两份日志：

因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。InnoDB 以插件形式引入 MySQL 后，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统（redo log）来实现 crash-safe 能力。 ==》即 InnoDB 通过 redo log 实现事务。

这两种日志有以下三点不同。

- **redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。**

- redo log 是物理日志，记录的是「在某个数据页上做了什么修改」；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如「给 id=2 这一行的 c 字段加 1 」。binlog 有两/三种模式，statement 格式的话是记 SQL 语句， row 格式会记录行的内容，记两条，更新前和更新后都有。

- redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。其中「追加写」是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

**执行器和 InnoDB 引擎在执行该 update 语句时的内部流程分析**

- 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 id = 2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。

- 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。

- 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。

- 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。

- 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。

该这个 update 语句的执行流程图如下：

> 红色部分表示在执行器中执行，其他为在 InnoDB 中执行。

```mermaid
graph LR
a1[<font color=red>取 id = 2 这一行] --> a2{数据页在内存中}
a2{数据页在内存中} --否--> b2[磁盘中读入内存]
a2 --是--> c2[返回行数据]
b2 --> c2
c2 --> d2[<font color=red>将这行的 c 值加 1]
d2 --> e2[<font color=red>写入新行]
e2 --> f2[新行更新到内存]
f2 --> g2[写入 redolog 处于 prepare 阶段]
g2 --> h2[<font color=red>写 binlog]
h2 --> i2[提交事务 处于 commit 状态]
```

### 两阶段提交

最后将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是「两阶段提交」。

「两阶段提交」为了让两份日志之间的逻辑一致。要说明这个问题，我们得从**怎样让数据库恢复到半个月内任意一秒的状态？**问题说起。

**数据恢复过程**：

前面我们说过了，binlog 会记录所有的逻辑操作，并且是采用「追加写」的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的「定期」取决于系统的重要性，可以是一天一备，也可以是一周一备。

当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：

- 首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；
- 然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。

这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。

**为什么日志需要「两阶段提交」。这里不妨用反证法来进行解释。**

由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。

仍然用前面的 update 语句来做例子。假设当前 id = 2 的行，字段 c 的值是 0，再假设**执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash**，会出现什么情况呢？

- **先写 redo log 后写 binlog**。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。
    但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。

- **先写 binlog 后写 redo log**。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。

因此如果不使用“两阶段提交”，**那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致**。

你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？

其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。

简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。

### 小结

- redo log 用于保证 crash-safe 能力。`innodb_flush_log_at_trx_commit` 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。`sync_binlog` 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。【线上两个参数值都是 1】
- binlog 用于记录了完整的逻辑记录，所有的逻辑记录在 binlog 里都能找到，所以在备份恢复时，是以 binlog 为基础，通过其记录的完整逻辑操作，备份出一个和原库完整的数据。

- 定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？

    备份时间周期的长短包括两个方面：

    首先，是恢复数据丢失的时间，既然需要恢复，肯定是数据丢失了。如果一天一备份的话，只要找到这天的全备，加入这天某段时间的 binlog 来恢复，如果一周一备份，假设是周一，而你要恢复的数据是周日某个时间点，那就，需要全备+周一到周日某个时间点的全部 binlog 用来恢复，时间相比前者需要增加很多；看业务能忍受的程度

    其次，是数据库丢失，如果一周一备份的话，需要确保整个一周的 binlog 都完好无损，否则将无法恢复；而一天一备，只要保证这天的 binlog 都完好无损；当然这个可以通过校验，或者冗余等技术来实现，相比之下，上面那点更重要。

