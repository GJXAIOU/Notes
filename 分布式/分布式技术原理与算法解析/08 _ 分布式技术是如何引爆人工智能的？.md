# 08 \| 分布式技术是如何引爆人工智能的？

作者: 聂鹏程

完成时间:

总结时间:

![](<https://static001.geekbang.org/resource/image/be/74/be73945681a79572d5a694c2c6bfd174.jpg>)

<audio><source src="https://static001.geekbang.org/resource/audio/64/eb/64af37922fbff2ccb613fb4b4d872aeb.mp3" type="audio/mpeg"></audio>

你好，我是聂鹏程。今天，我来继续带你打卡分布式核心技术。

通过前面课程，相信你已经对分布式的起源以及什么是分布式有了一定的了解，从用户留言来看很多同学对分布式技术、分布式技术的应用，以及分布式技术的重要性非常感兴趣。所以，我将以人工智能技术为例，带你了解分布式技术的应用及其重要性。

## 什么是人工智能？

2016年3月，Google AlphaGo以4:1的比分赢得了世界围棋冠军李世石。这场围棋人机大战，将人工智能技术推向了高潮。现在，人工智能已经广泛渗透到了我们的生活中，比如手机拍照美化、人脸识别、平安城市、自然语言处理、语音识别等。

那么，到底什么是人工智能呢？

所谓人工智能，其实就是希望机器能够模拟人的思维，像人一样智能。目前，对人工智能的定义大多可划分为四类，即机器**“像人一样思考”“像人一样行动”“理性地思考”和“理性地行动”。**这里的行动，指的是采取行动或制定行动的决策。

那人工智能是如何让机器像人那样智能呢？人并不是天生就会解决问题的，我们经常会听到一句经典的话“见多识广”，人遇到新的问题，是通过学习新知识，然后结合自己的经验去解决的。比如，人并不是生来就认识香蕉，而是通过后天的学习（包括学习香蕉的形状、颜色、口味等）来获取识别香蕉的经验，当下次再看到香蕉时，就知道这是香蕉了。

<!-- [[[read_end]]] -->

人工智能要模拟人的智能也类似，需要通过大量的数据进行学习和分析获得规律（即建立一个模型），然后利用该规律或模型对未知数据进行预测，以判断是否与建模数据具有相同特征。

从人工智能的定义可以看出，**数据、模型（也叫作算法）、算力**是人工智能的三大核心。在一定程度上可以说，数据决定了机器学习能达到的上限，模型提供了方法。因此**数据处理和模型训练是人工智能的关键技术，算力决定了数据处理和模型训练的实用性能，而分布式技术就是解决算力的不二妙招。**

接下来，我就对数据处理和模型训练进行具体分析，来帮助你了解人工智能中需要用到哪些分布式技术来解决算力问题。

## 数据处理

数据处理又称数据预处理，是指通过数据统计、数据集成、数据清理、数据规约、数据变换等方法，对数据缺失、数据噪声、数据冗余、多数据源等问题进行处理以得到高质量数据，为模型训练提供高质量输入，是人工智能不可缺少的环节。

其实，**数据处理类似于我们的知识整理过程。**一个精心打造的、体系化梳理过的专栏文章，可以帮助我们在学习一门课程时，少走弯路、避免踩雷、达到事半功倍的效果。同样地，一个精心处理过的数据集，对于人工智能的模型训练也能起到事半功倍的效果，一方面可以缩短机器学习的周期，另一方面也可以提高机器学习的质量。

所以接下来，我们就一起看看数据预处理的方法吧。

**数据统计（Data Statistics）。**数据统计是数据预处理的第一步，其范围、规模、方式等会直接影响数据分析的结果。常见的统计特征有最大值、最小值、均值、中位数、方差、标准差等。

**数据集成（Data Integration）。**数据的收集有多种途径，比如文件数据、数据库数据、问卷数据等，而不同的数据源，其数据的存储方式、命名规则、单位等不尽相同，所以我们需要数据集成来将多个数据源的数据整合到一起，以保证数据结构、属性的一致性，并去除冗余数据，方便后续分析。

**数据清理（Data Cleaning）。**由于用户忘记或设备损坏，经常会造成部分数据缺失；由于仪器故障或用户填写错误，经常会出现数据错误（噪声数据）等。如果不对这些数据做任何处理，后面的模型训练过程将产生严重偏差。数据清理过程就是用来解决这个问题的，它可以通过平均值或众数等来填充丢失值或修改这些噪声值。

**数据规约（Data Reduction）。**由于机器学习中的数据量很大，因此会导致很多重复的特征，或者很多不重要的特征（比如ID号等）。数据规约通常指通过主成分分析法 (Principal Component Analysis，PCA)、小波变换(Wavelet Transform，WT)等方法去除重复特征及不重要的特征，从而减少数据的维度或者数据量，降低问题复杂度，同时不影响后面训练的结果。

**数据变换（Data Conversion）。**数据变化是指通过标准化、离散化和分层化等方法对数据进行集成、清理、规约等操作，使得数据更加一致、更加容易被模型处理。数据变换方法主要有数据标准化、数据离散化和数据泛化三类。

可以看出，**数据预处理虽然很复杂，但可以拆分成多个步骤进行**。对于小样本数据处理时，单台机器的处理能力就足够了，所以采用单台机器进行处理即可。但是对于大规模数据来说，单台机器的处理能力已成为瓶颈，此时，不得不需要分布式数据处理了。

目前，业界已经有很多大数据处理软件，比如分布式计算框架MapReduce、Spark，分布式存储框架HDFS、HBase等，来进行分布式数据处理。

> 备注：我会在专栏的“第三站：分布式计算技术”和“第五站：分布式数据存储”与你详细讲述这些框架。

接下来，我们再一起看看分布式如何助力模型训练。

## 分布式模型训练

在了解什么是分布式模型训练之前，我们先看一下什么是模型训练。

### 什么是分布式模型训练？

**模型训练就是从已知数据中找到规律**。具体来说就是，不断通过已有数据进行学习寻找规律，并进行验证增强，最终给出最适合的模型参数，并根据该模型参数对给定的未知数据进行预测。

比如有一堆橘子和西瓜，可以通过模型训练得到：大的、绿色的判定为西瓜，小的、黄色的判定为橘子。那么当给出一个未知数据时，我们通过它的大小及颜色信息就可以判断该水果是橘子还是西瓜。这就是模型训练。

其中，大小和颜色属于预测的两个特征，而它们的具体数值（比如，大于10厘米等，颜色RGB的数值范围）就是模型参数。

随着大数据时代的到来，人工智能技术逐渐向大规模训练数据、大模型训练等方向发展。比如，百度的Deep Speech 2系统使用了11940小时的语音数据以及超过200万句表述来训练英语的语音识别模型；2011年谷歌训练出拥有十亿个参数的超大神经网络模型。很明显，单台计算机的存储能力、计算能力已经不能满足了，因此分布式模型训练诞生了。

研究表明，在具有 GPU加速卡的单机上，采用**ImageNet 数据集，完成一次训练大概需要多达一周的时间。**这还仅仅只是一次训练迭代的时间，如果是比较严格的生产级业务，至少需要数十次迭代，训练累计时间将会达到数十周。试想一下，如果一个业务仅仅是模型训练就花费数十周，那么等到真正上线，恐怕最佳时间窗口也已经过去了。

在多台机器上的分布式训练无疑能极大减少训练时间，近期研究中，基于**ImageNet数据集**，采用包含**2048个GPU 的集群将训练时间降低到了4分钟**。TensorFlow是由Google开源且在业内非常流行的机器学习计算框架，它的分布式版本利用了 GPU 加速服务器的虚拟化集群，将深度学习的**训练时间从数周缩短到数小时。**

总结来讲，分布式训练可以大大提升训练效率，大幅缩短训练时间，从而缩短业务面市周期，所以各大公司都在研究分布式训练，比如华为、IBM、阿里巴巴等。

那，什么是分布式模型训练呢？

**分布式模型训练**是利用分布式集群，将多个计算机的存储能力、计算能力等进行统一管理和调度，从而实现模型训练。

可以看到，分布式模型训练的前提是有一个**分布式集群**，因此一个高效、可靠的分布式集群是基础。而这个分布式集群的**架构、选主、调度、可靠性**等关键技术，奠定了分布式模型训练的基础。

> 备注：关于分布式集群的架构和调度，我会在本专栏的“第二站：分布式资源管理与负载调度”进行详细讲解；关于集群的选主，我已经在本专栏的“第一站：分布式协调与同步”中进行了讲解；而关于可靠性，我会在在本专栏的“第六站：分布式高可靠”进行讲解。

好了，有了分布式集群作为基础，接下来，我们要考虑的就是如何进行分布式模型训练了。不同的场景，采用的分布式模型训练的方法也不一样，主要包括数据分布式训练、模型分布式训练和混合模型训练三类。

接下来，我将带你了解这三种分布式模型训练模式，并带你了解其中涉及的分布式技术。

### 数据分布式训练

数据分布式训练主要是针对大规模训练数据的场景。如下图所示，数据分布式训练是在每个节点（假设，一台服务器代表一个节点）上都存储或运行一个完整的模型训练程序的基础上，将大规模数据进行划分，然后将划分后的数据子集分配到多个节点上，每个节点根据自己接收到的数据进行训练。

![](<https://static001.geekbang.org/resource/image/8c/c2/8c3197afef4ca27cc155df39fcf64dc2.jpg?wh=3000*608>)

每个节点会根据自己拥有的数据子集训练出一个子模型，并按照一定的规则与其他节点通信，比如各节点向其他节点传递本节点的子模型参数或参数更新等信息，以有效整合来自各个节点的训练结果，来得到全局的机器学习模型。比如，每个节点训练一个子模型得到自己的参数，最终的模型为多个节点的参数取平均值。

可以看出，数据分布式有如下两个重要信息：

1. 数据需拆分存储到不同的节点进行训练，因此涉及了**数据的拆分方法、数据的分布式存储和管理**，其中数据拆分方法主要有两类，对训练样本进行划分和对每个样本的维度进行划分，这是非常基础的方法。目前，市面上大部分的书籍均有介绍，如果你感兴趣的话可以自行学习。
2. **节点之间需要通信交互信息。**分布式通信是实现任何分布式技术的底座，没有分布式通信技术，分布式模型训练犹如纸上谈兵。

<!-- -->

> 备注：数据的分布式存储和管理，是数据分布式的基础，我会在“第五站：分布式数据存储”中与你详细讲述；而关于分布式通信的相关技术，我会在“第四站：分布式通信技术”与你介绍。

### 模型分布式训练

了解了数据分布式训练，我们再来看一下模型分布式训练。它针对的主要是大模型训练场景，在分布式领域中也被称为任务并行或任务分布式。

如下图所示，模型分布式训练是指将大模型进行拆分，然后将拆分后的子模型分配到不同的节点上进行训练。与数据分布式训练不同的是，首先每个节点上只存储和运行部分模型训练程序，而不是完整的模型训练程序；其次，各个子模型之间存在较强的依赖关系，比如节点1的输出是节点2和节点3子模型的输入，因此节点之间需要进行中间计算结果的通信。

![](<https://static001.geekbang.org/resource/image/89/e4/89efd0455d8397a1331f546686ba35e4.jpg?wh=2999*892>)

可以看出，模型分布式训练包含如下两个关键信息：

1. 大模型拆分为多个小模型，其本质是将大任务拆分为多个子任务，这其实就是**分而治之策略**。而子任务之间的拆分，需要运用包括**流水线、MapReduce等**在内的多种分布式计算模式。
2. 不同节点上的子任务之间，需要通过通信交互中间计算结果，涉及分布式通信技术。

<!-- -->

> 备注：任务拆分和流水线等分布式计算模式是模型分布式训练不可缺少的技术，我会在“第三站：分布式计算技术”与你详细介绍；而关于分布式通信的相关技术，你可以移步“第四站：分布式通信技术”中进行了解。

### 混合模型训练

混合模型训练，主要是针对大规模训练数据和大模型训练共存的场景。

所谓混合模型训练，就是将数据分布式训练和模型分布式训练结合起来。如下图所示，假设有一个多GPU集群系统，首先对模型进行拆分，将子模型分配到单节点上不同的GPU，然后对数据进行划分，每个节点负责训练一部分数据，最后进行模型参数同步，得到全局参数和全局模型。

![](<https://static001.geekbang.org/resource/image/f9/ef/f96f4bc09fd9f95ddf9610b21d94e2ef.jpg?wh=3195*1011>)

从混合模型训练的流程可以看出：

- 单节点或多节点实现模型并行或模型分布式训练，涉及模型拆分、并行与分布式计算模式等；
- 多节点之间实现了数据分布式训练，涉及数据的拆分方法和数据的分布式存储和管理等技术；
- 单节点之间的模型分布式训练，需要单节点上多进程之间通信；多节点之间的分布式训练需要跨节点跨进程通信。

<!-- -->

> 备注：我会在“第三站：分布式计算技术”“第四站：分布式通信技术”和“第五站：分布式数据存储”模块中，与你讲述这其中涉及的分布式技术。

## 总结

讲完分布式模型训练，这节课就告一段落了。分布式训练可以将深度学习的训练时间从数周缩短到数小时，极大提升了训练效率，这充分说明了分布式技术的重要性。接下来，我们一起总结下今天的主要内容吧。

首先，我与你介绍了什么是人工智能，让你先对其有了一个整体的理解。

然后，我与你介绍了人工智能中的数据预处理方法，包括数据清理、数据统计、数据集成、数据规约、数据变换等，在这其中分布式数据预处理是处理大规模数据的一个很好的方式。

最后，我与你介绍了分布式模型训练，包括数据分布式训练、模型分布式训练和混合模型训练3种方法，并介绍了其中涉及的关键分布式技术，比如数据的分布式存储和管理、分布式通信等。没有这些关键的分布式技术，分布式模型训练其实就是空谈了。

现在，我将人工智能中涉及的关键分布式技术整理为了一张表格，以方便你学习。

![](<https://static001.geekbang.org/resource/image/3b/43/3b626dcb58d4cec1b405e3c24eed0943.jpg?wh=3326*2456>)

我是聂鹏程，感谢你的收听，欢迎你在评论区给我留言分享你的观点，也欢迎你把这篇文章分享给更多的朋友一起阅读。我们下期再会！

## 精选留言(15)

- ![img](08%20_%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%98%AF%E5%A6%82%E4%BD%95%E5%BC%95%E7%88%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%EF%BC%9F.resource/resize,m_fill,h_34,w_34.jpeg)

  忆水寒

  我一直以为这篇文章是对前面几篇文章的答疑呢

  作者回复: 从前面几篇文章用户留言来看，很多同学对分布式技术、分布式技术的应用以及分布式技术的重要性非常感兴趣。所以，在今天这篇答疑文章中，我以人工智能技术为例，带你了解分布式技术的应用及其重要性。 大家留言里的疑惑，我会通过回复的形式陆续进行解答。本篇的答疑相当于既是一个答疑，也是赠送给大家的一个额外福利：）

  2019-10-09

  **3

  **8

- ![img](08%20_%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%98%AF%E5%A6%82%E4%BD%95%E5%BC%95%E7%88%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%EF%BC%9F.resource/resize,m_fill,h_34,w_34-16622229628121383.jpeg)

  tt

  把本章的总结放在本课课后。  分布式协调 分布式协调算法的目的是为了使得分布式系统内的节点有序。这里有序的含义可以分为两个方面，这两个方面也可以按**程序等于算法➕数据结构**或者“业务等于业务规则➕业务数据模型”的事件，分为集群内节点动作的有序性和被节点操作的资源的状态的有序性两个方面。 # 1、算法、规则、业务逻辑等的有序性。 1.1、访问临界资源时有序，这时需要分布式互斥。 协调多个进程获取权限和根据权限有序访问共享资源，“获得访问权限的进程可以访问共享资源，其他进程必须等待拥有该权限的进程释放权限”。 获取访问权的方式有如下几种: - 霸道总裁：集中式算法。 - 民主协商：分布式算法。 - 轮值 CEO：令牌环算法。 1.2、分布式访问用到的权限是由分布式锁来代表，获取锁的进程就拥有了权限。 分布式锁有如下几种： - 基于数据库的分布式锁。 - 基于缓存的分布式锁。 - 基于ZOOKEEPER的分布式锁。 2、算法、规则、业务逻辑的执行主体——节点选主的有序性。 为了高可用，集群内选主节点的有序。 2.1、分布式共识 分布式的选主，本质是一个**分布式共识**的过程——就关于谁是主节点这一状态在集群内达成共识的过程。 2.2、选主的算法 选主算法需要考虑的事选举的速度、算法实现的难易程度，以及是否会过于频繁的出发选主、切主的动作。 - MongoDB采用Bully算法，谁或者而且睡的节点ID大谁就是主节点。 - Google 开源的 Kubernetes，为了保证可靠性，通常会部署 3 个节点用于数据备份。这 3 个节点中，有一个会被选为主，其他节点作为备。Kubernetes 的选主采用的是开源的 etcd 组件。而etcd 的集群管理器 etcds，是一个高可用、强一致性的服务发现存储仓库，就是采用了 Raft 算法来实现选主和一致性的。 - Zoo keeper使用ZAB(ZooKeeper Atomic Broadcast)算法。相较于 Raft 算法的投票机制，ZAB 算法增加了通过节点 ID 和数据 ID 作为参考进行选主，节点 ID 和数据 ID 越大，表示数据越新，优先成为主。相比较于 Raft 算法，ZAB 算法尽可能保证数据的最新性。所以，ZAB 算法可以说是对 Raft 算法的改进。选举过程中，在某一轮中如果有一个server ID 最大的节点，则会直接结束选举。 3、算法、规则、业务逻辑的执行客体——资源也即数据的分布式一致性——分布式事物 分布式事物是多个事物组成的。事物的特征是ACID，即原子性、一致性、隔离性和持久性。他们其实都是关于数据状态的，保证并发（隔离性）前提下数据的强一致性。 另外还有保证数据最终一致性的BASE理论。 实现分布式事物有三种方法，分别是采用强一致性的XA两阶段提交和XA三阶段提交以及采用最终一致性的基于消息的一致性方法。 前两种方法是阻塞式的，必须用到锁，用锁就会降低性能，此外如果在执行过程中某些节点或网络出现故障，仍然无法保证数据不一致的问题。 说到性能，自然想起异步方式，没错，使用消息的机制。提高性能的同时，异步实现一致性时，解决出错问题的手段就是重试。因为反正系统已经解耦了，某个节点可以根据需要进行必要的操作，还不会影响其它节点。 > 对于银行系统来说，对账从核心与外围数据一致性的角度来看，就是一个“异步重试”的过程。 3.1、对于数据一致性，还有CAP理论 这个理论对数据的描述比事物更全面，除了一致性还描述了数据的可用性（服务是为数据服务的）和数据的分区容错性。 对于一致性，CAP理论的视野也更高，强调系统内节点所有的数据是一致的，不论这些数据是不是涉及事物；而且这里的一致性涵盖了强一致性和最终一致性：最终一致性用于在保证可用性和分区容错性的情景中。

  作者回复: 👍👍，加油！

  2020-03-13

  **

  **7

- ![img](08%20_%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%98%AF%E5%A6%82%E4%BD%95%E5%BC%95%E7%88%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%EF%BC%9F.resource/resize,m_fill,h_34,w_34-16622229628121384.jpeg)

  aoe

  人工智能有一道数学的高墙，对于我来说已经倒在了单机

  作者回复: 加油，分布式AI可是趋势哟！

  2019-10-19

  **

  **6

- ![img](08%20_%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%98%AF%E5%A6%82%E4%BD%95%E5%BC%95%E7%88%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%EF%BC%9F.resource/resize,m_fill,h_34,w_34-16622229628121385.jpeg)

  zhaozp

  打卡文章学习：      1、人工智能离不开数据的处理，模型的训练，分布式技术能够为训练提供算力。主要分为三个方面的训练：数据分布式训练、模型分布式训练和混合模型训练。也再次说明了分布式技术是人工智能的基石。      今天这篇文章应该算是个福利，了解了部分人工智能、深度学习的基本知识点。谢谢老师

  作者回复: 不积小流无以成江海，加油！

  2019-10-09

  **

  **3

- ![img](08%20_%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%98%AF%E5%A6%82%E4%BD%95%E5%BC%95%E7%88%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%EF%BC%9F.resource/resize,m_fill,h_34,w_34-16622229628121386.jpeg)

  钱

  分布式技术确实重要，尤其是当硬件升级不再灵验的时候，正如老师所言网络通信技术是所有分布式技术的底座，分布式技术的复杂性也来源网络通信环境的不确定性。好像几位瞎子在一起完成一件事情，只能通过声音来进行交互，不过每位瞎子都是各自独立的并且声音会因传递或环境因素而失真。那要完成一件事情，大家都需要参与并且信息也能同步到位着实不易。

  2020-02-15

  **

  **1

- ![img](08%20_%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%98%AF%E5%A6%82%E4%BD%95%E5%BC%95%E7%88%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%EF%BC%9F.resource/resize,m_fill,h_34,w_34-16622229628121387.jpeg)

  张理查

  分布式技术原理与算法#Day9 人工智能是什么？ 人工智能是数据喂出来的，需要通过大量的数据进行学习和分析获得规律（模型），然后利用该规律对未知数据进行预测，进而判断是否与建模数据有相同特征。 因此人工智能关注数据、算法（模型）以及算力。数据处理、模型训练是人工智能的关键技术，算力保证了前两者的性能。分布式的入场可以为人工智能带来算力的提升。 具体来看一看人工智能的关键步骤 • 分布式数据处理： 也就是数据的预处理，提高训练数据的质量，为模型提供高质量输入 • 数据统计 • 数据集成 • 数据清洗 • 数据规约 • 数据变换 这些步骤都可以采用大数据处理软件，利用分布式计算框架、分布式存储框架来解决。 • 分布式模型训练：实际还是利用集群作为基础，进行分布式的模型训练，提升训练效率。 • 数据分布式训练：大数据拆小数据 • 模型分布式训练：大模型拆小模型 • 混合模型训练：上两种并存

  2019-12-27

  **

  **2

- ![img](08%20_%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%98%AF%E5%A6%82%E4%BD%95%E5%BC%95%E7%88%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%EF%BC%9F.resource/resize,m_fill,h_34,w_34-16622229628121388.jpeg)

  鸭先知

  又是一个宏大的应用场景

  2020-03-31

  **

  **

- ![img](08%20_%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%98%AF%E5%A6%82%E4%BD%95%E5%BC%95%E7%88%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%EF%BC%9F.resource/resize,m_fill,h_34,w_34-16622229628121389.jpeg)

  亢（知行合一的路上）

  对模型分布式训练有了大概了解，公司里面有些机器，晚上不使用，也可以用来做成集群进行模型训练，虽单台性能没有服务器那么强大，可很多台合在一起，也许会有大威力😄

  作者回复: 👍👍

  2020-03-19

  **

  **1

- ![img](08%20_%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%98%AF%E5%A6%82%E4%BD%95%E5%BC%95%E7%88%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%EF%BC%9F.resource/resize,m_fill,h_34,w_34-16622229628121387.jpeg)

  张理查

  • 人工智能是什么？ 人工智能是数据喂出来的，需要通过大量的数据进行学习和分析获得规律（模型），然后利用该规律对未知数据进行预测，进而判断是否与建模数据有相同特征。 因此人工智能关注数据、算法（模型）以及算力。数据处理、模型训练是人工智能的关键技术，算力保证了前两者的性能。分布式的入场可以为人工智能带来算力的提升。 具体来看一看人工智能的关键步骤 • 分布式数据处理： 也就是数据的预处理，提高训练数据的质量，为模型提供高质量输入 • 数据统计 • 数据集成 • 数据清洗 • 数据规约 • 数据变换 这些步骤都可以采用大数据处理软件，利用分布式计算框架、分布式存储框架来解决。 • 分布式模型训练：实际还是利用集群作为基础，进行分布式的模型训练，提升训练效率。 • 数据分布式训练：大数据拆小数据 • 模型分布式训练：大模型拆小模型 • 混合模型训练：上两种并存

  2019-12-25

  **

  **

- ![img](08%20_%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%98%AF%E5%A6%82%E4%BD%95%E5%BC%95%E7%88%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%EF%BC%9F.resource/resize,m_fill,h_34,w_34-16622229628131390.jpeg)

  Eternal

  老师可不可以分享一下，如果想要学习人工智能AI，怎么学习数学呢？

  2019-10-26

  **

  **

- ![img](08%20_%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%98%AF%E5%A6%82%E4%BD%95%E5%BC%95%E7%88%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%EF%BC%9F.resource/resize,m_fill,h_34,w_34-16622229628131391.jpeg)

  和你一起搬砖的胡大爷

  现在的ML虽然叫分布式训练，但是思路还是怎么把batch拆开，怎么处理梯度，从而发展起来的各种奇技淫巧，比如ring all reducer这种。分布式训练和更偏重的是从机器学习算法出发的调优，而不是广义上的分布式。训练的方法也往往和模型紧密相关，resnet和vgg的技巧就完全就不一样。

  2019-10-14

  **

  **

- ![img](08%20_%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%98%AF%E5%A6%82%E4%BD%95%E5%BC%95%E7%88%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%EF%BC%9F.resource/132.jpeg)

  易儿易

  看完以后觉得人工智能采用分布式只是解决了算力问题呀，如果有单台超级计算机同样可以做到……不知道说的对不对

  2019-10-11

  **1

  **

- ![img](08%20_%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%98%AF%E5%A6%82%E4%BD%95%E5%BC%95%E7%88%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%EF%BC%9F.resource/resize,m_fill,h_34,w_34-16622229628131392.jpeg)

  周涛

  粗浅的认识到，模型就是算法，任务在节点间分配以及结果在节点间通信。

  2019-10-10

  **

  **

- ![img](08%20_%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%98%AF%E5%A6%82%E4%BD%95%E5%BC%95%E7%88%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%EF%BC%9F.resource/resize,m_fill,h_34,w_34-16622229628131393.jpeg)

  blackpiglet

  "单节点实现模型分布式训练，涉及模型拆分、并行与分布式计算模式..." 应该是改成 “多节点...” 吧？

  作者回复: “单节点或多节点实现模型并行或模型分布式训练，涉及模型拆分、并行与分布式计算模式……”改成这样会更严谨一点。 谢谢提醒！已修改。请继续保持这种学习+思考+分享的习惯！加油！

  2019-10-10

  **

  **1

- ![img](08%20_%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%98%AF%E5%A6%82%E4%BD%95%E5%BC%95%E7%88%86%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%EF%BC%9F.resource/resize,m_fill,h_34,w_34-16622229628131394.jpeg)

  Dale

  原来是通过人工智能来引入分布式的应用呀，启动后续的章节

  2019-10-09
